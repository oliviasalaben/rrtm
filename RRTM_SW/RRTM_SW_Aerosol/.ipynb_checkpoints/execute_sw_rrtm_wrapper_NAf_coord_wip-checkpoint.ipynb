{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d2dcf8-ef5a-4091-b223-bbd5381027df",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Module: Run SW RRTM Wrapper (sw_rrtm_wrapper.ipynb)\n",
    "\n",
    "Created on 2024\n",
    "\n",
    "@authors: Olivia Salaben and Jianyu Zheng\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce01a81a-dc24-4a23-ad19-ec3b3adf40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039959ea-eb58-44b4-87ea-9971862a7575",
   "metadata": {
    "tags": []
   },
   "source": [
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "import nbformat\n",
    "\n",
    "def execute_notebook(notebook_path):\n",
    "    with open(notebook_path) as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    # Create an instance of the ExecutePreprocessor class\n",
    "    executor = ExecutePreprocessor(timeout=-1)\n",
    "    \n",
    "    # Execute the notebook\n",
    "    executor.preprocess(nb, {'metadata': {'path': '.'}})\n",
    "    \n",
    "    print(\"Notebook executed successfully.\")\n",
    "\n",
    "# Specify the path to the notebook you want to execute\n",
    "notebook_path = \"/my_run_rrtm_sw_coord.ipynb\"\n",
    "\n",
    "# Call the execute_notebook function with the notebook path\n",
    "execute_notebook(notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4281e75d-14e5-4241-a747-5c22b7cbfdee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF4 data model, file format HDF5):\n",
      "    dimensions(sizes): lon(144), lat(96)\n",
      "    variables(dimensions): float32 lon(lon), float32 lat(lat), float32 isza_DJF(lat, lon), float32 isza_MAM(lat, lon), float32 isza_JJA(lat, lon), float32 isza_SON(lat, lon)\n",
      "    groups: \n"
     ]
    }
   ],
   "source": [
    "#----------\n",
    "# using Ashok's isolation weighted data from 2006\n",
    "#----------\n",
    "\n",
    "sza_Dataset = Dataset('inso_weighted_SZA_seasonal_DustCOMMgrid.nc')\n",
    "print(sza_Dataset) #[DJF, JJA, MAM, SON,lat,lon]\n",
    "\n",
    "lat_sza = np.array(sza_Dataset.variables['lat'][:])\n",
    "lon_sza = np.array(sza_Dataset.variables['lon'][:])\n",
    "sza_weighted_DJF = np.array(sza_Dataset.variables['isza_DJF'][:])\n",
    "sza_weighted_JJA = np.array(sza_Dataset.variables['isza_JJA'][:])\n",
    "sza_weighted_MAM = np.array(sza_Dataset.variables['isza_MAM'][:])\n",
    "sza_weighted_SON = np.array(sza_Dataset.variables['isza_SON'][:])\n",
    "\n",
    "sza_weighted_all = [sza_weighted_DJF,sza_weighted_MAM,sza_weighted_JJA, sza_weighted_SON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9346e871-96a9-40e7-a221-475647a31b80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-177.5 -175.  -172.5 -170.  -167.5 -165.  -162.5 -160.  -157.5 -155.\n",
      " -152.5 -150.  -147.5 -145.  -142.5 -140.  -137.5 -135.  -132.5 -130.\n",
      " -127.5 -125.  -122.5 -120.  -117.5 -115.  -112.5 -110.  -107.5 -105.\n",
      " -102.5 -100.   -97.5  -95.   -92.5  -90.   -87.5  -85.   -82.5  -80.\n",
      "  -77.5  -75.   -72.5  -70.   -67.5  -65.   -62.5  -60.   -57.5  -55.\n",
      "  -52.5  -50.   -47.5  -45.   -42.5  -40.   -37.5  -35.   -32.5  -30.\n",
      "  -27.5  -25.   -22.5  -20.   -17.5  -15.   -12.5  -10.    -7.5   -5.\n",
      "   -2.5    0.     2.5    5.     7.5   10.    12.5   15.    17.5   20.\n",
      "   22.5   25.    27.5   30.    32.5   35.    37.5   40.    42.5   45.\n",
      "   47.5   50.    52.5   55.    57.5   60.    62.5   65.    67.5   70.\n",
      "   72.5   75.    77.5   80.    82.5   85.    87.5   90.    92.5   95.\n",
      "   97.5  100.   102.5  105.   107.5  110.   112.5  115.   117.5  120.\n",
      "  122.5  125.   127.5  130.   132.5  135.   137.5  140.   142.5  145.\n",
      "  147.5  150.   152.5  155.   157.5  160.   162.5  165.   167.5  170.\n",
      "  172.5  175.   177.5  180. ]\n"
     ]
    }
   ],
   "source": [
    "#Re-order -180 to be +180 and move to end of array and reorder sza data\n",
    "lon_sza[lon_sza == -180] = 180\n",
    "lon_sza = np.sort(lon_sza)\n",
    "print(lon_sza)\n",
    "\n",
    "sza_weighted_DJF = np.concatenate((sza_weighted_DJF[:,1:],sza_weighted_DJF[:,:1]), axis=1)\n",
    "sza_weighted_MAM = np.concatenate((sza_weighted_MAM[:,1:],sza_weighted_MAM[:,:1]), axis=1)\n",
    "sza_weighted_JJA = np.concatenate((sza_weighted_JJA[:,1:],sza_weighted_JJA[:,:1]), axis=1)\n",
    "sza_weighted_SON = np.concatenate((sza_weighted_SON[:,1:],sza_weighted_SON[:,:1]), axis=1)\n",
    "\n",
    "sza_weighted_all = [sza_weighted_DJF,sza_weighted_MAM,sza_weighted_JJA, sza_weighted_SON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da6da1c8-1b57-4155-8bf5-959587d7d639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Create run for all seasons\n",
    "seasons = [0,1,2,3]\n",
    "seas_name= ['DJF','MAM','JJA','SON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4fd0a0-1f2b-40e2-b32f-724a656bf7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in MODIS surface albedo data\n",
    "MERRA_data = Dataset('MERRA2_400.tavgM_2d_rad_Nx.202301.nc4')\n",
    "MERRA_data_lat = np.array(MERRA_data.variables['lat'][:])\n",
    "MERRA_data_lon = np.array(MERRA_data.variables['lon'][:])\n",
    "new_match_lat_index = np.load('new_match_lat_index.npy')\n",
    "new_match_lon_index = np.load('new_match_lon_index.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f82fb4c-e915-4e8e-94a7-d033e7c0294c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_month_albedo(year, month):\n",
    "    filename = f'MERRA2_400.tavgM_2d_rad_Nx.{year}{month:02}.nc4'\n",
    "    dataset = Dataset(filename)\n",
    "    albedo = np.array(dataset.variables['ALBEDO'][0])\n",
    "    return albedo\n",
    "\n",
    "albedo_2023 = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    albedo_2023.append(get_month_albedo(2023, month))\n",
    "\n",
    "albedo_2023 = np.array(albedo_2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae8a35d4-962b-411b-a7fd-66da1e75fc49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DJF_merra2_albedo_2023 = np.zeros((len(new_match_lat_index),len(new_match_lon_index)))\n",
    "MAM_merra2_albedo_2023 = np.zeros((len(new_match_lat_index),len(new_match_lon_index)))\n",
    "JJA_merra2_albedo_2023 = np.zeros((len(new_match_lat_index),len(new_match_lon_index)))\n",
    "SON_merra2_albedo_2023 = np.zeros((len(new_match_lat_index),len(new_match_lon_index)))\n",
    "for ilon in range(len(new_match_lon_index)):\n",
    "    for ilat in range(len(new_match_lat_index)):\n",
    "        DJF_merra2_albedo_2023[ilat,ilon] = (albedo_2023[11,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[0,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[1,new_match_lat_index[ilat],new_match_lon_index[ilon]])/3\n",
    "        MAM_merra2_albedo_2023[ilat,ilon] = (albedo_2023[2,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[3,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[4,new_match_lat_index[ilat],new_match_lon_index[ilon]])/3                \n",
    "        JJA_merra2_albedo_2023[ilat,ilon] = (albedo_2023[5,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[6,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[7,new_match_lat_index[ilat],new_match_lon_index[ilon]])/3\n",
    "        SON_merra2_albedo_2023[ilat,ilon] = (albedo_2023[8,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[9,new_match_lat_index[ilat],new_match_lon_index[ilon]] + albedo_2023[10,new_match_lat_index[ilat],new_match_lon_index[ilon]])/3\n",
    "        \n",
    "all_merra2_albedo_2023 = [DJF_merra2_albedo_2023, MAM_merra2_albedo_2023, JJA_merra2_albedo_2023, SON_merra2_albedo_2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188965e-1acd-46fa-b404-3facea1b1bac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Later, calculate bulk seasonal DustCOMM DAOD by season -look at North African dust SW DREE method code\n",
    "#----------\n",
    "# using DustCOMM 2021 papers b) https://dustcomm.atmos.ucla.edu/\n",
    "# specifically https://dustcomm.atmos.ucla.edu/data/K21b/ dataset DustCOMM_source_region_DAOD_seas_bin_abs.nc\n",
    "# assumes aspherical dust shape, PM20 dust\n",
    "#----------\n",
    "\n",
    "daod_Dustcomm_PM20_Dataset = Dataset('DustCOMM_source_region_DAOD_annual_bin_abs.nc')\n",
    "print(daod_Dustcomm_PM20_Dataset) #[season,source,diameter,lat,lon,bin]\n",
    "\n",
    "lat_Dustcomm_PM20 = np.array(daod_Dustcomm_PM20_Dataset.variables['lat'][:])\n",
    "lon_Dustcomm_PM20 = np.array(daod_Dustcomm_PM20_Dataset.variables['lon'][:])\n",
    "mean_Daod_Dustcomm_20PM = np.array(daod_Dustcomm_PM20_Dataset.variables['Mean'][:])\n",
    "#dustcomm_seas = np.array(daod_Dustcomm_PM20_Dataset.variables['season'][:])\n",
    "\n",
    "bin_NAf_dust_loading = mean_loading_Dustcomm_20PM[:,:,:,0] + mean_loading_Dustcomm_20PM[:,:,:,1] + mean_loading_Dustcomm_20PM[:,:,:,2]\n",
    "#bulk_NAf_dust_loading\n",
    "bin_Sarahan_laoding = mean_loading_Dustcomm_20PM[:,:,:,0] + mean_loading_Dustcomm_20PM[:,:,:,1]\n",
    "bin_Sahelian_loading = mean_loading_Dustcomm_20PM[:,:,:,2]\n",
    "print(total_North_African_loading.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd0ac097-38e7-4c8b-b659-d39a26b0568a",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import papermill as pm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Function to execute notebook for given parameters\n",
    "def execute_notebook(season, ilat, ilon, output_file):\n",
    "    notebook_path = \"my_run_rrtm_sw_coord.ipynb\"\n",
    "    output_notebook_path = f\"NAf_dust_notebook_lat{lat_sza[ilat]:.2f}_lon{lon_sza[ilon]:.2f}_seas{seas_name[season]}_coord.ipynb\"\n",
    "\n",
    "    # Redirect standard output to a file\n",
    "    sys.stdout = open(output_file, 'w')\n",
    "\n",
    "    pm.execute_notebook(\n",
    "        notebook_path,\n",
    "        output_notebook_path,\n",
    "        parameters=dict(\n",
    "            Rs=float(all_merra2_albedo_2023[season][ilat, ilon]),\n",
    "            sza=float(sza_weighted_all[season][ilat, ilon]),\n",
    "            season=float(season),\n",
    "            lat=float(\"{:.2f}\".format(lat_sza[ilat])),\n",
    "            lon=float(\"{:.2f}\".format(lon_sza[ilon]))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Restore standard output\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "    if os.path.exists(output_notebook_path):\n",
    "        print(f\"Notebook executed successfully for season {seas_name[season]} with parameters Rs={all_merra2_albedo_2023[season][ilat,ilon]}, sza={sza_weighted_all[season][ilat,ilon]}, lat={lat_sza[ilat]}, and lon={lon_sza[ilon]}. Output saved as '{output_notebook_path}'.\")\n",
    "    else:\n",
    "        print(f\"Error: The output notebook '{output_notebook_path}' was not generated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Run notebook with different combinations of parameters.')\n",
    "    parser.add_argument('season', type=int, help='Season index (0=DJF, 1=MAM, 2=JJA, 3=SON)')\n",
    "    parser.add_argument('ilat', type=int, help='Latitude index')\n",
    "    parser.add_argument('ilon', type=int, help='Longitude index')\n",
    "    parser.add_argument('--output_file', type=str, default='output.log', help='Output file to save the execution log (default: output.log)')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    execute_notebook(args.season, args.ilat, args.ilon, args.output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88f3004-d34a-4b91-88e9-9b10bfa4ea70",
   "metadata": {},
   "source": [
    "## Load DustCOMM North African bulk dust seasonal DAOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8efcb-48c2-486a-89b1-61721d1b1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------\n",
    "# using DustCOMM 2021 papers b) https://dustcomm.atmos.ucla.edu/\n",
    "# specifically https://dustcomm.atmos.ucla.edu/data/K21b/ dataset DustCOMM_source_region_DAOD_seas_bin_abs.nc\n",
    "# assumes aspherical dust shape, PM20 dust\n",
    "#----------\n",
    "\n",
    "#bulk DAOD data\n",
    "daod_Dustcomm_PM20_Dataset = Dataset('../../Dust_Optical_Properties/DustCOMM_source_region_DAOD_seas_PM20_abs.nc')\n",
    "print(daod_Dustcomm_PM20_Dataset) #[season,source,diameter,lat,lon,bin]\n",
    "\n",
    "lat_Dustcomm_PM20 = np.array(daod_Dustcomm_PM20_Dataset.variables['lat'][:])\n",
    "lon_Dustcomm_PM20 = np.array(daod_Dustcomm_PM20_Dataset.variables['lon'][:])\n",
    "mean_Daod_Dustcomm_20PM = np.array(daod_Dustcomm_PM20_Dataset.variables['Mean'][:])\n",
    "#dustcomm_seas = np.array(daod_Dustcomm_PM20_Dataset.variables['season'][:])\n",
    "dustcomm_Sources_PM20 = np.array(daod_Dustcomm_PM20_Dataset.variables['source'][:]) \n",
    "\n",
    "#Create seasonal North African DAOD as a function of lat and lon\n",
    "NAf_Daod_Dustcomm_20PM = mean_Daod_Dustcomm_20PM[:,:,0,:] + mean_Daod_Dustcomm_20PM[:,:,1,:] + mean_Daod_Dustcomm_20PM[:,:,2,:]\n",
    "\n",
    "DJF_NAf_Daod_Dustcomm_20PM = NAf_Daod_Dustcomm_20PM[:,:,0]\n",
    "MAM_NAf_Daod_Dustcomm_20PM = NAf_Daod_Dustcomm_20PM[:,:,1]\n",
    "JJA_NAf_Daod_Dustcomm_20PM = NAf_Daod_Dustcomm_20PM[:,:,2]\n",
    "SON_NAf_Daod_Dustcomm_20PM = NAf_Daod_Dustcomm_20PM[:,:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e3727-8a14-4624-a00b-aee919d37e4a",
   "metadata": {},
   "source": [
    "## Multiply: (SW DRE/column RRTM DAOD) * DustCOMM North African Dust DAOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eccc6a-470b-41fb-8a73-25cd25bfa3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rrtm_env",
   "language": "python",
   "name": "rrtm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
